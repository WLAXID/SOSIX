
# SOSIX — автономный браузерный агент

SOSIX — экспериментальный автономный агент для управления браузером через Playwright и LLM (NVIDIA API). Он делает итеративный цикл: анализ страницы → решение (JSON) → действие, с упором на семантику элементов, а не на хардкод-селекторы.

## Демонстрация работы

https://www.youtube.com/watch?v=18zg7Vbu3cg

## Быстрый старт

1) Установите зависимости:

```powershell
python -m pip install -r requirements.txt
```

2) Установите API-ключ (по умолчанию `NVIDIA_API_KEY` в окружении):

```powershell
setx NVIDIA_API_KEY "ваш_api_ключ"
```

или в .env (нужно создать)

```.env
NVIDIA_API_KEY=nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

3) Запуск:

```powershell
python main.py
```

После старта вводите задачи на естественном языке (ru/en). Примеры: "Найди iPhone 14 на Avito", "Включи видео на YouTube — Meshuggah Bleed".
Настройки в `config.json`.
Ключи и секреты лучше хранить в переменных окружения

## Как это работает (кратко)

- `main.py` запускает `BrowserAgent`.
- `TaskAnalyzer` извлекает цель и флаг риска.
- `BrowserAgent` получает стартовый URL (LLM) и загружает страницу.
- `PageAnalyzer` возвращает `search_hints` (FILL, BUTTONS, LINKS и т.д.).
- Контекст отправляется в LLM, который возвращает строгое JSON-решение.
- `DecisionValidator` парсит JSON → `ActionExecutor` выполняет действие через Playwright.

## Основные ограничения и безопасность
- Может ошибаться и требовать вмешательства/коррекции (`wait_for_user_action`).
- Не гарантируется корректный checkout/оплата на произвольных сайтах.
- Для рискованных действий (платёж/удаление) агент запрашивает подтверждение (НЕ ТЕСТИЛ, ВРЯД ЛИ РАБОТАЕТ).
- В текущем виде имеет ужасный CLI!!!

## Структура проекта (основное)

- `main.py` — точка входа
- `browser_agent.py` — координатор цикла анализа/действия
- `page_analyzer.py` — извлечение текста и подсказок
- `action_executor.py` — построение локаторов и выполнение действий
- `decision_validator.py` — строгая валидация решений LLM
- `disambiguation_layer.py` — progressive narrowing
- `nvidia_api.py` — клиент LLM
- `config_loader.py`, `config.json` — конфиг
- `logger.py` — цветные логи и UX консоли

## Советы по отладке

- Включите `logging.level = DEBUG` в `config.json` для подробных логов.
- Если модель возвращает некорректный JSON — смотрите raw-ответы в логах.

## Идея Сосикса

Этот проект - пятая версия браузерного агента. До неё было ещё четыре попытки, три из которых были основаны на vision-моделях. Небольшой прикол: все три работали нестабильно. Иногда они угадывали, иногда промахивались, иногда видели кнопку там, где её не существовало, а иногда кликали плюс-минус в никуда. В какой-то момент стало очевидно, что vision-модель думает не в пикселях, а в примерных пикселях. Для человека это окей (нет), а для автоматизации - путь в Вальхаллу. Да и к тому же обрабатывать каждый раз изображение это жутко дорого и долго. После этого осознания vision был удалён из реализации. Текущая версия полностью построена на обычной text-to-text LLM, агентной логике и поиске элементов через DOM и семантику, а не через координаты и "угадай где кнопка"

## Ограничения

ТЗ изначально выглядело так, будто агент должен уметь всё и сразу. Читать почту, удалять спам, заказывать еду, покупать билеты, жить в браузере, не ломаться, не тупить и вообще быть маленьким цифровым Аллахом. На практике быстро выяснилось, что универсальный агент - это миф (в рамках фактического проектирования одного-двух дней). Поиск информации, клик по кнопке `Play` и полноценный checkout с оплатой - это задачи разного класса. Их нельзя честно решить одной и той же логикой без превращения архитектуры в макароны. Поэтому текущая реализация - это осознанный компромисс. Агент умеет автономно работать в браузере, принимать решения, анализировать страницу, искать элементы без хардкода, логировать свои действия и останавливаться, когда требуется подтверждение пользователя. При этом он не притворяется магом и не делает вид, что может стабильно оформить заказ на любом сайте без специализированной логики. Я его даже капчу находить научил!.. но решать сами будете))

Отмечу, что никакие заранее прописанные сценарии действий здесь не используются (ну возможно чут-чут). Агент не знает, где кнопка `купить`, не знает, что страница вакансий это обязательно `/vacancies` (но что ему мешает прочитать URL?), и не живёт по заготовленному плану. Он принимает решения на лету, ошибается, получает фидбек от среды и либо продвигается дальше, либо застревает. Это не баг, а отражение реальности. Браузерная автоматизация в живом интернете - это не линейный скрипт, а постоянная борьба с UX, который вообще не рад, что его кто-то автоматизирует. Вот сайт Пятёрочки у меня с VPN открываться вообще отказался: я проходил капчу 20 раз и он все равно не верил, что я человек.. ну, тогда будем дудосить агентами Магнит

## История разработки

На весь проект было потрачено три дня (на v5 - 1 день, на v5.1 ещё полдня). Хуярил я практически без остановки, потому что было слишком интересно. Это был скорее вызов самому себе, чем попытка просто сделать тестовое задание. Идея создать условного конкурента техногигантам в виде своего Claude-агента оказалась сильнее здравого смысла. Где-то в середине стало понятно, что задача в полной формулировке почти невыполнима в текущих временных рамках, но останавливаться уже было поздно. Было интересно, где именно всё окончательно сломается

Теперь про экономику агента. За всё время проекта было выкурено ровно ноль сигарет. Не потому что я святой, а потому что я наконец-то бросил курить. Это, возможно, главный успех всей разработки. По деньгам: примерно 150 рублей ушло на аккаунты Gmail, чтобы зарегать 5-7 GitHub-акков и поабузить бесплатный доступ к API кодинг-моделей. Ещё около 50 рублей ушло на подтверждение доступа к NVIDIA API. Отдельное спасибо NVIDIA за то, что они решили принимать только немецкий номер телефона, это было неожиданно и приятно. Кстати, по умолчанию юзается модель `mistral-small-3.1-24b-instruct-2503`. Кто хочет - ставьте умнее типу `mistralai/mistral-large-3-675b-instruct-2512` и сидите в таймауте - модели с большим количеством параметров вызывают `API Error 429: Too Many Requests`. Зато из плюсов `large` моделей - то что они умнее `small`, соответственно, план и реализация действий будет выполняться с большей точностью.

Итого: примерно 200 рублей общих затрат против условных 999 миллионов долларов, которые OpenAI и др. потратили на свои агенты. Вот и думайте, кто тут на самом деле победил

Проект далёк от идеала, но он честный. Он показывает реальные ограничения, реальные проблемы и реальные точки, где универсальный агент перестаёт быть универсальным. Это не демонстрация магии, а демонстрация границ. И если честно, именно это в нём самое ценное



